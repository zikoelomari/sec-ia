{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Protocole de Quantification - G√©n√©ration de Code & S√©curit√©\n",
        "\n",
        "Ce notebook analyse les rapports de campagne pour quantifier les risques li√©s au code g√©n√©r√© par IA.\n",
        "\n",
        "## M√©thodologie exp√©rimentale\n",
        "\n",
        "### Dataset de prompts\n",
        "- **Source** : `prompts/prompts_50.json` (50 prompts vari√©s orient√©s s√©curit√©)\n",
        "- **Domaines couverts** : authentification, CRUD, upload, parsing, crypto, JWT, SQL, subprocess, YAML, pickle, secrets\n",
        "- **Langages** : Python, JavaScript, TypeScript, Java, C#\n",
        "\n",
        "### Variabilit√© probabiliste\n",
        "- **Runs par prompt** : 3-5 g√©n√©rations par prompt (configurable via `--runs-per-prompt`)\n",
        "- **Seed optionnel** : Contr√¥le de la reproductibilit√© via `--seed`\n",
        "- **Variations** : Templates alternatifs, choix al√©atoire de patterns, insertion de variantes\n",
        "\n",
        "### Normalisation\n",
        "- **LOC** : Comptage des lignes non vides par snippet/run\n",
        "- **M√©triques** : Vuln√©rabilit√©s / 1k LOC (global et par scanner)\n",
        "- **S√©v√©rit√©s** : Distribution HIGH/MEDIUM/LOW\n",
        "- **Cat√©gories** : Injection, secrets, exec/eval, subprocess, crypto, auth, deserialization, etc.\n",
        "\n",
        "### Limitations\n",
        "- G√©n√©ration simul√©e (pas de vrai mod√®le IA)\n",
        "- Scanners d√©pendants de l'environnement (Bandit/Semgrep/Snyk)\n",
        "- Pas de normalisation par complexit√© cyclomatique\n",
        "- Comparaison IA vs OSS limit√©e aux rapports disponibles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n",
        "import statistics\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Configuration\n",
        "ANALYSES_DIR = Path(\"analyses\")\n",
        "PROMPTS_FILE = Path(\"prompts/prompts_50.json\")\n",
        "\n",
        "print(f\"üìÅ R√©pertoire analyses: {ANALYSES_DIR}\")\n",
        "print(f\"üìÑ Fichier prompts: {PROMPTS_FILE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Chargement des donn√©es\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Charger les prompts de r√©f√©rence\n",
        "if PROMPTS_FILE.exists():\n",
        "    with open(PROMPTS_FILE, 'r', encoding='utf-8') as f:\n",
        "        prompts_data = json.load(f)\n",
        "    print(f\"‚úÖ {len(prompts_data)} prompts charg√©s\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Fichier prompts introuvable: {PROMPTS_FILE}\")\n",
        "    prompts_data = []\n",
        "\n",
        "# Lister les rapports de campagne\n",
        "campaign_files = list(ANALYSES_DIR.glob(\"campaign_*.json\"))\n",
        "individual_reports = list(ANALYSES_DIR.glob(\"campaign_*_*.json\"))\n",
        "print(f\"üìä Rapports de campagne agr√©g√©s: {len(campaign_files)}\")\n",
        "print(f\"üìä Rapports individuels: {len(individual_reports)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Charger tous les rapports de campagne\n",
        "campaigns = []\n",
        "for campaign_file in campaign_files:\n",
        "    try:\n",
        "        with open(campaign_file, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "            campaigns.append(data)\n",
        "            print(f\"‚úÖ {campaign_file.name}: {data.get('campaign_id', 'unknown')}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur chargement {campaign_file.name}: {e}\")\n",
        "\n",
        "# Charger les rapports individuels\n",
        "individual_data = []\n",
        "for report_file in individual_reports:\n",
        "    try:\n",
        "        with open(report_file, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "            individual_data.append(data)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erreur chargement {report_file.name}: {e}\")\n",
        "\n",
        "print(f\"\\nüìà Total: {len(campaigns)} campagnes, {len(individual_data)} rapports individuels\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Calcul des m√©triques\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_lines_of_code(file_path: str) -> int:\n",
        "    \"\"\"Compte les lignes non vides d'un fichier.\"\"\"\n",
        "    try:\n",
        "        path = Path(file_path)\n",
        "        if path.exists():\n",
        "            with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "                return sum(1 for line in f if line.strip())\n",
        "    except:\n",
        "        pass\n",
        "    return 0\n",
        "\n",
        "def extract_findings_from_report(report: dict) -> list:\n",
        "    \"\"\"Extrait toutes les findings d'un rapport (Bandit, Semgrep, Snyk, detector).\"\"\"\n",
        "    findings = []\n",
        "    \n",
        "    # Bandit\n",
        "    bandit_data = report.get(\"scans\", {}).get(\"bandit\", {})\n",
        "    if bandit_data and isinstance(bandit_data, dict):\n",
        "        for issue in bandit_data.get(\"results\", []):\n",
        "            findings.append({\n",
        "                \"scanner\": \"bandit\",\n",
        "                \"severity\": issue.get(\"issue_severity\", \"UNKNOWN\").upper(),\n",
        "                \"test_id\": issue.get(\"test_id\", \"\"),\n",
        "                \"category\": classify_category(issue.get(\"test_id\", \"\")),\n",
        "            })\n",
        "    \n",
        "    # Semgrep\n",
        "    semgrep_data = report.get(\"scans\", {}).get(\"semgrep\", {})\n",
        "    if semgrep_data and isinstance(semgrep_data, dict):\n",
        "        for issue in semgrep_data.get(\"results\", []):\n",
        "            severity = issue.get(\"severity\", \"UNKNOWN\").upper()\n",
        "            if severity not in [\"HIGH\", \"MEDIUM\", \"LOW\"]:\n",
        "                severity = \"MEDIUM\"  # Normalisation\n",
        "            findings.append({\n",
        "                \"scanner\": \"semgrep\",\n",
        "                \"severity\": severity,\n",
        "                \"check_id\": issue.get(\"check_id\", \"\"),\n",
        "                \"category\": classify_semgrep_category(issue.get(\"check_id\", \"\")),\n",
        "            })\n",
        "    \n",
        "    # Snyk\n",
        "    snyk_data = report.get(\"scans\", {}).get(\"snyk\", {})\n",
        "    if snyk_data and isinstance(snyk_data, dict):\n",
        "        for issue in snyk_data.get(\"issues\", []):\n",
        "            severity = issue.get(\"severity\", \"UNKNOWN\").upper()\n",
        "            findings.append({\n",
        "                \"scanner\": \"snyk\",\n",
        "                \"severity\": severity,\n",
        "                \"id\": issue.get(\"id\", \"\"),\n",
        "                \"category\": classify_snyk_category(issue.get(\"id\", \"\")),\n",
        "            })\n",
        "    \n",
        "    # Gemini detector (patterns)\n",
        "    patterns = report.get(\"summary\", {}).get(\"patterns\", {})\n",
        "    if patterns:\n",
        "        for pattern_name, count in patterns.items():\n",
        "            if count > 0:\n",
        "                findings.append({\n",
        "                    \"scanner\": \"detector\",\n",
        "                    \"severity\": \"MEDIUM\",  # Patterns sont g√©n√©ralement MEDIUM\n",
        "                    \"pattern\": pattern_name,\n",
        "                    \"category\": classify_pattern(pattern_name),\n",
        "                })\n",
        "    \n",
        "    return findings\n",
        "\n",
        "def classify_category(test_id: str) -> str:\n",
        "    \"\"\"Classifie une finding Bandit par cat√©gorie.\"\"\"\n",
        "    test_id = test_id.upper()\n",
        "    if test_id.startswith(\"B102\") or test_id.startswith(\"B603\") or test_id.startswith(\"B604\"):\n",
        "        return \"injection\"\n",
        "    if test_id.startswith(\"B105\") or test_id.startswith(\"B106\") or test_id.startswith(\"B107\"):\n",
        "        return \"secrets\"\n",
        "    if \"CRYPTO\" in test_id or test_id.startswith(\"B3\") or test_id.startswith(\"B4\"):\n",
        "        return \"crypto\"\n",
        "    if \"SUBPROCESS\" in test_id or \"POPEN\" in test_id:\n",
        "        return \"subprocess\"\n",
        "    if \"EXEC\" in test_id or \"EVAL\" in test_id:\n",
        "        return \"exec_eval\"\n",
        "    return \"autre\"\n",
        "\n",
        "def classify_semgrep_category(check_id: str) -> str:\n",
        "    \"\"\"Classifie une finding Semgrep par cat√©gorie.\"\"\"\n",
        "    check_id = check_id.lower()\n",
        "    if \"sql\" in check_id or \"injection\" in check_id:\n",
        "        return \"injection\"\n",
        "    if \"secret\" in check_id or \"password\" in check_id or \"token\" in check_id:\n",
        "        return \"secrets\"\n",
        "    if \"crypto\" in check_id or \"encrypt\" in check_id:\n",
        "        return \"crypto\"\n",
        "    if \"subprocess\" in check_id or \"shell\" in check_id:\n",
        "        return \"subprocess\"\n",
        "    if \"exec\" in check_id or \"eval\" in check_id:\n",
        "        return \"exec_eval\"\n",
        "    if \"auth\" in check_id or \"jwt\" in check_id:\n",
        "        return \"auth\"\n",
        "    if \"pickle\" in check_id or \"deserialize\" in check_id:\n",
        "        return \"deserialization\"\n",
        "    return \"autre\"\n",
        "\n",
        "def classify_snyk_category(issue_id: str) -> str:\n",
        "    \"\"\"Classifie une finding Snyk par cat√©gorie.\"\"\"\n",
        "    issue_id = issue_id.lower()\n",
        "    if \"sql\" in issue_id or \"injection\" in issue_id:\n",
        "        return \"injection\"\n",
        "    if \"secret\" in issue_id:\n",
        "        return \"secrets\"\n",
        "    return \"autre\"\n",
        "\n",
        "def classify_pattern(pattern_name: str) -> str:\n",
        "    \"\"\"Classifie un pattern d√©tect√© par cat√©gorie.\"\"\"\n",
        "    pattern_name = pattern_name.lower()\n",
        "    if \"injection\" in pattern_name or \"sql\" in pattern_name:\n",
        "        return \"injection\"\n",
        "    if \"secret\" in pattern_name or \"token\" in pattern_name or \"password\" in pattern_name:\n",
        "        return \"secrets\"\n",
        "    if \"subprocess\" in pattern_name:\n",
        "        return \"subprocess\"\n",
        "    if \"exec\" in pattern_name:\n",
        "        return \"exec_eval\"\n",
        "    return \"autre\"\n",
        "\n",
        "print(\"‚úÖ Fonctions de calcul des m√©triques d√©finies\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculer les m√©triques pour tous les rapports individuels\n",
        "metrics_data = []\n",
        "\n",
        "for report in individual_data:\n",
        "    metadata = report.get(\"metadata\", {})\n",
        "    file_path = metadata.get(\"path\", \"\")\n",
        "    loc = count_lines_of_code(file_path)\n",
        "    \n",
        "    findings = extract_findings_from_report(report)\n",
        "    \n",
        "    # Compter par s√©v√©rit√©\n",
        "    severity_counts = Counter(f[\"severity\"] for f in findings)\n",
        "    \n",
        "    # Compter par scanner\n",
        "    scanner_counts = Counter(f[\"scanner\"] for f in findings)\n",
        "    \n",
        "    # Compter par cat√©gorie\n",
        "    category_counts = Counter(f.get(\"category\", \"autre\") for f in findings)\n",
        "    \n",
        "    # Risk score\n",
        "    risk_score = report.get(\"summary\", {}).get(\"risk_score\", 0)\n",
        "    \n",
        "    metrics_data.append({\n",
        "        \"file_path\": file_path,\n",
        "        \"loc\": loc,\n",
        "        \"total_findings\": len(findings),\n",
        "        \"severity_high\": severity_counts.get(\"HIGH\", 0),\n",
        "        \"severity_medium\": severity_counts.get(\"MEDIUM\", 0),\n",
        "        \"severity_low\": severity_counts.get(\"LOW\", 0),\n",
        "        \"scanner_bandit\": scanner_counts.get(\"bandit\", 0),\n",
        "        \"scanner_semgrep\": scanner_counts.get(\"semgrep\", 0),\n",
        "        \"scanner_snyk\": scanner_counts.get(\"snyk\", 0),\n",
        "        \"scanner_detector\": scanner_counts.get(\"detector\", 0),\n",
        "        \"risk_score\": risk_score,\n",
        "        \"findings\": findings,\n",
        "        \"category_counts\": dict(category_counts),\n",
        "        \"campaign\": metadata.get(\"campaign\", \"\"),\n",
        "        \"run_index\": metadata.get(\"run_index\", 0),\n",
        "    })\n",
        "\n",
        "print(f\"‚úÖ M√©triques calcul√©es pour {len(metrics_data)} rapports\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculer les m√©triques globales\n",
        "total_loc = sum(m[\"loc\"] for m in metrics_data)\n",
        "total_findings = sum(m[\"total_findings\"] for m in metrics_data)\n",
        "total_high = sum(m[\"severity_high\"] for m in metrics_data)\n",
        "total_medium = sum(m[\"severity_medium\"] for m in metrics_data)\n",
        "total_low = sum(m[\"severity_low\"] for m in metrics_data)\n",
        "\n",
        "# Vuln√©rabilit√©s / 1k LOC\n",
        "vuln_per_1kloc = (total_findings / total_loc * 1000) if total_loc > 0 else 0\n",
        "\n",
        "# Par scanner\n",
        "bandit_findings = sum(m[\"scanner_bandit\"] for m in metrics_data)\n",
        "semgrep_findings = sum(m[\"scanner_semgrep\"] for m in metrics_data)\n",
        "snyk_findings = sum(m[\"scanner_snyk\"] for m in metrics_data)\n",
        "detector_findings = sum(m[\"scanner_detector\"] for m in metrics_data)\n",
        "\n",
        "bandit_per_1kloc = (bandit_findings / total_loc * 1000) if total_loc > 0 else 0\n",
        "semgrep_per_1kloc = (semgrep_findings / total_loc * 1000) if total_loc > 0 else 0\n",
        "snyk_per_1kloc = (snyk_findings / total_loc * 1000) if total_loc > 0 else 0\n",
        "detector_per_1kloc = (detector_findings / total_loc * 1000) if total_loc > 0 else 0\n",
        "\n",
        "# Risk scores\n",
        "risk_scores = [m[\"risk_score\"] for m in metrics_data if m[\"risk_score\"] > 0]\n",
        "avg_risk_score = statistics.mean(risk_scores) if risk_scores else 0\n",
        "std_risk_score = statistics.stdev(risk_scores) if len(risk_scores) > 1 else 0\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üìä M√âTRIQUES GLOBALES\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"LOC total: {total_loc}\")\n",
        "print(f\"Findings total: {total_findings}\")\n",
        "print(f\"Vuln / 1k LOC: {vuln_per_1kloc:.2f}\")\n",
        "print(f\"\\nS√©v√©rit√©s:\")\n",
        "print(f\"  HIGH: {total_high}\")\n",
        "print(f\"  MEDIUM: {total_medium}\")\n",
        "print(f\"  LOW: {total_low}\")\n",
        "print(f\"\\nPar scanner / 1k LOC:\")\n",
        "print(f\"  Bandit: {bandit_per_1kloc:.2f}\")\n",
        "print(f\"  Semgrep: {semgrep_per_1kloc:.2f}\")\n",
        "print(f\"  Snyk: {snyk_per_1kloc:.2f}\")\n",
        "print(f\"  Detector: {detector_per_1kloc:.2f}\")\n",
        "print(f\"\\nRisk Score: {avg_risk_score:.2f} ¬± {std_risk_score:.2f}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Visualisations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Graphique 1: Distribution des s√©v√©rit√©s\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "severities = [\"HIGH\", \"MEDIUM\", \"LOW\"]\n",
        "counts = [total_high, total_medium, total_low]\n",
        "colors = [\"#dc3545\", \"#ffc107\", \"#28a745\"]\n",
        "bars = ax.bar(severities, counts, color=colors)\n",
        "ax.set_xlabel(\"S√©v√©rit√©\")\n",
        "ax.set_ylabel(\"Nombre de findings\")\n",
        "ax.set_title(\"Distribution des s√©v√©rit√©s\")\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{int(height)}', ha='center', va='bottom')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Graphique 2: Vuln√©rabilit√©s / 1k LOC par cat√©gorie\n",
        "category_totals = defaultdict(int)\n",
        "category_loc = defaultdict(int)\n",
        "\n",
        "for m in metrics_data:\n",
        "    for category, count in m[\"category_counts\"].items():\n",
        "        category_totals[category] += count\n",
        "        category_loc[category] += m[\"loc\"]\n",
        "\n",
        "category_vuln_per_1kloc = {\n",
        "    cat: (category_totals[cat] / category_loc[cat] * 1000) if category_loc[cat] > 0 else 0\n",
        "    for cat in category_totals.keys()\n",
        "}\n",
        "\n",
        "# Trier par valeur d√©croissante\n",
        "sorted_categories = sorted(category_vuln_per_1kloc.items(), key=lambda x: x[1], reverse=True)\n",
        "top_categories = dict(sorted_categories[:10])  # Top 10\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "categories = list(top_categories.keys())\n",
        "values = list(top_categories.values())\n",
        "bars = ax.barh(categories, values, color='steelblue')\n",
        "ax.set_xlabel(\"Vuln√©rabilit√©s / 1k LOC\")\n",
        "ax.set_ylabel(\"Cat√©gorie\")\n",
        "ax.set_title(\"Vuln√©rabilit√©s / 1k LOC par cat√©gorie (Top 10)\")\n",
        "for i, (bar, val) in enumerate(zip(bars, values)):\n",
        "    ax.text(val, bar.get_y() + bar.get_height()/2,\n",
        "            f'{val:.2f}', ha='left', va='center')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Graphique 3: Vuln√©rabilit√©s / 1k LOC par scanner\n",
        "scanner_data = {\n",
        "    \"Bandit\": bandit_per_1kloc,\n",
        "    \"Semgrep\": semgrep_per_1kloc,\n",
        "    \"Snyk\": snyk_per_1kloc,\n",
        "    \"Detector\": detector_per_1kloc,\n",
        "}\n",
        "scanner_data = {k: v for k, v in scanner_data.items() if v > 0}\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "scanners = list(scanner_data.keys())\n",
        "values = list(scanner_data.values())\n",
        "bars = ax.bar(scanners, values, color=['#007bff', '#28a745', '#ffc107', '#dc3545'][:len(scanners)])\n",
        "ax.set_xlabel(\"Scanner\")\n",
        "ax.set_ylabel(\"Vuln√©rabilit√©s / 1k LOC\")\n",
        "ax.set_title(\"Vuln√©rabilit√©s / 1k LOC par scanner\")\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{height:.2f}', ha='center', va='bottom')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Graphique 4: Heatmap simple IA vs OSS (si disponible)\n",
        "# Chercher des rapports OSS pour comparaison\n",
        "oss_reports = [r for r in individual_data if \"repo\" in r.get(\"metadata\", {}).get(\"type\", \"\").lower()]\n",
        "ia_reports = [r for r in individual_data if \"campaign\" in r.get(\"metadata\", {}).get(\"type\", \"\").lower()]\n",
        "\n",
        "if oss_reports and ia_reports:\n",
        "    # Calculer m√©triques IA vs OSS\n",
        "    ia_findings = sum(len(extract_findings_from_report(r)) for r in ia_reports)\n",
        "    ia_loc = sum(count_lines_of_code(r.get(\"metadata\", {}).get(\"path\", \"\")) for r in ia_reports)\n",
        "    ia_vuln_per_1kloc = (ia_findings / ia_loc * 1000) if ia_loc > 0 else 0\n",
        "    \n",
        "    oss_findings = sum(len(extract_findings_from_report(r)) for r in oss_reports)\n",
        "    oss_loc = sum(count_lines_of_code(r.get(\"metadata\", {}).get(\"path\", \"\")) for r in oss_reports)\n",
        "    oss_vuln_per_1kloc = (oss_findings / oss_loc * 1000) if oss_loc > 0 else 0\n",
        "    \n",
        "    # Heatmap simple\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "    data = [[ia_vuln_per_1kloc], [oss_vuln_per_1kloc]]\n",
        "    im = ax.imshow(data, cmap='YlOrRd', aspect='auto')\n",
        "    ax.set_xticks([0])\n",
        "    ax.set_xticklabels(['Vuln / 1k LOC'])\n",
        "    ax.set_yticks([0, 1])\n",
        "    ax.set_yticklabels(['IA', 'OSS'])\n",
        "    ax.set_title(\"Comparaison IA vs OSS\")\n",
        "    \n",
        "    # Ajouter les valeurs\n",
        "    for i in range(2):\n",
        "        text = ax.text(0, i, f'{data[i][0]:.2f}', ha=\"center\", va=\"center\", color=\"black\", fontweight='bold')\n",
        "    \n",
        "    plt.colorbar(im, ax=ax)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Donn√©es OSS insuffisantes pour comparaison\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. R√©sum√© ex√©cutif et recommandations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top 5 cat√©gories dominantes\n",
        "top_5_categories = dict(sorted(category_totals.items(), key=lambda x: x[1], reverse=True)[:5])\n",
        "\n",
        "# Top 5 r√®gles/scanners qui d√©tectent le plus\n",
        "scanner_findings = {\n",
        "    \"bandit\": bandit_findings,\n",
        "    \"semgrep\": semgrep_findings,\n",
        "    \"snyk\": snyk_findings,\n",
        "    \"detector\": detector_findings,\n",
        "}\n",
        "top_5_scanners = dict(sorted(scanner_findings.items(), key=lambda x: x[1], reverse=True)[:5])\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"üìã R√âSUM√â EX√âCUTIF\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nüî¥ Top 5 cat√©gories dominantes:\")\n",
        "for i, (cat, count) in enumerate(top_5_categories.items(), 1):\n",
        "    print(f\"  {i}. {cat}: {count} findings\")\n",
        "\n",
        "print(f\"\\nüîç Top 5 scanners (par nombre de d√©tections):\")\n",
        "for i, (scanner, count) in enumerate(top_5_scanners.items(), 1):\n",
        "    print(f\"  {i}. {scanner}: {count} findings\")\n",
        "\n",
        "print(f\"\\nüìä M√©triques cl√©s:\")\n",
        "print(f\"  - Vuln√©rabilit√©s / 1k LOC: {vuln_per_1kloc:.2f}\")\n",
        "print(f\"  - Risk Score moyen: {avg_risk_score:.2f} ¬± {std_risk_score:.2f}\")\n",
        "print(f\"  - Distribution: HIGH={total_high}, MEDIUM={total_medium}, LOW={total_low}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# G√©n√©rer 5 recommandations actionnables\n",
        "recommendations = []\n",
        "\n",
        "# 1. Secure prompts\n",
        "if total_high > 0:\n",
        "    recommendations.append({\n",
        "        \"priorit√©\": \"HAUTE\",\n",
        "        \"recommandation\": \"Utiliser des prompts s√©curis√©s avec validation explicite des entr√©es utilisateur\",\n",
        "        \"action\": \"R√©viser les prompts pour inclure des instructions de validation et sanitization\"\n",
        "    })\n",
        "\n",
        "# 2. Revues de code\n",
        "if vuln_per_1kloc > 10:\n",
        "    recommendations.append({\n",
        "        \"priorit√©\": \"HAUTE\",\n",
        "        \"recommandation\": \"Mettre en place des revues de code syst√©matiques pour le code g√©n√©r√©\",\n",
        "        \"action\": \"Instaurer un processus de review obligatoire avant merge\"\n",
        "    })\n",
        "\n",
        "# 3. CI gates\n",
        "if total_high > 5:\n",
        "    recommendations.append({\n",
        "        \"priorit√©\": \"MOYENNE\",\n",
        "        \"recommandation\": \"Ajouter des gates CI/CD pour bloquer les builds avec vuln√©rabilit√©s HIGH\",\n",
        "        \"action\": \"Configurer les workflows GitHub Actions pour √©chouer sur HIGH findings\"\n",
        "    })\n",
        "\n",
        "# 4. Secrets management\n",
        "if \"secrets\" in top_5_categories:\n",
        "    recommendations.append({\n",
        "        \"priorit√©\": \"HAUTE\",\n",
        "        \"recommandation\": \"Am√©liorer la gestion des secrets (pas de hardcoding, utilisation de vaults)\",\n",
        "        \"action\": \"Former les d√©veloppeurs sur l'utilisation de variables d'environnement et secrets managers\"\n",
        "    })\n",
        "\n",
        "# 5. Sandbox scans\n",
        "if \"subprocess\" in top_5_categories or \"exec_eval\" in top_5_categories:\n",
        "    recommendations.append({\n",
        "        \"priorit√©\": \"MOYENNE\",\n",
        "        \"recommandation\": \"Ex√©cuter des scans dans un environnement sandbox pour d√©tecter les ex√©cutions dangereuses\",\n",
        "        \"action\": \"Mettre en place des scans dynamiques en plus des scans statiques\"\n",
        "    })\n",
        "\n",
        "# Afficher les recommandations\n",
        "print(\"\\nüí° RECOMMANDATIONS ACTIONNABLES\\n\")\n",
        "for i, rec in enumerate(recommendations[:5], 1):\n",
        "    print(f\"{i}. [{rec['priorit√©']}] {rec['recommandation']}\")\n",
        "    print(f\"   ‚Üí Action: {rec['action']}\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
